# AEGIS Performance CI Gate
# Sprint 25: Automated performance regression detection
#
# Triggers: PR to main, pushes to main, manual dispatch
# Runs Criterion benchmarks and compares against baselines

name: Performance Gate

on:
  push:
    branches: [main]
    paths:
      - 'node/**'
      - '.github/workflows/performance.yml'
  pull_request:
    branches: [main]
    paths:
      - 'node/**'
  workflow_dispatch:

env:
  CARGO_TERM_COLOR: always
  RUSTFLAGS: -Dwarnings

jobs:
  benchmarks:
    name: Criterion Benchmarks
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./node

    steps:
      - uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-action@stable
        with:
          components: rustfmt, clippy

      - name: Cache cargo registry
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            node/target
          key: ${{ runner.os }}-cargo-bench-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-bench-
            ${{ runner.os }}-cargo-

      - name: Download baseline (main branch)
        if: github.event_name == 'pull_request'
        uses: actions/cache@v4
        with:
          path: ./node/target/criterion
          key: criterion-baseline-${{ github.base_ref }}
          restore-keys: |
            criterion-baseline-main

      - name: Run Criterion benchmarks
        run: |
          cargo bench --bench performance -- --noplot 2>&1 | tee benchmark-results.txt

      - name: Extract benchmark results
        id: extract
        run: |
          # Extract key performance metrics
          echo "Extracting benchmark results..."

          # WAF benchmarks
          WAF_CLEAN=$(grep -A1 "WAF/clean_request" benchmark-results.txt | grep "time:" | head -1 | sed 's/.*\[\(.*\)\].*/\1/' | awk '{print $1}')
          WAF_SQLI=$(grep -A1 "WAF/sqli_detection" benchmark-results.txt | grep "time:" | head -1 | sed 's/.*\[\(.*\)\].*/\1/' | awk '{print $1}')

          # Route matching benchmarks
          ROUTE_COMPILED=$(grep -A1 "CompiledRouteMatching/regex_match" benchmark-results.txt | grep "time:" | head -1 | sed 's/.*\[\(.*\)\].*/\1/' | awk '{print $1}')

          # TLS fingerprint benchmarks
          TLS_FULL=$(grep -A1 "TLSFingerprint/compute_full" benchmark-results.txt | grep "time:" | head -1 | sed 's/.*\[\(.*\)\].*/\1/' | awk '{print $1}')

          # CRDT benchmarks
          CRDT_INCR=$(grep -A1 "CRDT/increment" benchmark-results.txt | grep "time:" | head -1 | sed 's/.*\[\(.*\)\].*/\1/' | awk '{print $1}')

          echo "WAF clean request: ${WAF_CLEAN:-N/A}"
          echo "WAF SQLi detection: ${WAF_SQLI:-N/A}"
          echo "Compiled route matching: ${ROUTE_COMPILED:-N/A}"
          echo "TLS fingerprint: ${TLS_FULL:-N/A}"
          echo "CRDT increment: ${CRDT_INCR:-N/A}"

          # Check for regressions (look for "regressed" or significant increases)
          REGRESSION_COUNT=$(grep -c "regressed" benchmark-results.txt || echo "0")
          echo "regression_count=$REGRESSION_COUNT" >> $GITHUB_OUTPUT

          if [ "$REGRESSION_COUNT" -gt "0" ]; then
            echo "::warning::Performance regression detected in $REGRESSION_COUNT benchmark(s)"
            grep -B5 "regressed" benchmark-results.txt || true
          fi

      - name: Performance threshold check
        run: |
          # Check critical performance targets
          echo "Checking performance thresholds..."

          FAILED=0

          # Check WAF < 100μs target
          WAF_TIME=$(grep -A1 "WAF/clean_request" benchmark-results.txt | grep "time:" | head -1 | sed 's/.*\[\(.*\) µs.*/\1/' | awk '{print $1}')
          if [ ! -z "$WAF_TIME" ]; then
            # Remove any non-numeric characters and compare
            WAF_NUM=$(echo "$WAF_TIME" | tr -d '[:alpha:][:space:]')
            if [ $(echo "$WAF_NUM > 100" | bc -l 2>/dev/null || echo "0") -eq 1 ]; then
              echo "::error::WAF analysis exceeds 100μs target: ${WAF_TIME}μs"
              FAILED=1
            else
              echo "✓ WAF analysis: ${WAF_TIME}μs (target: <100μs)"
            fi
          fi

          # Check compiled route matching < 1μs target
          ROUTE_TIME=$(grep -A1 "CompiledRouteMatching/regex_match" benchmark-results.txt | grep "time:" | head -1 | sed 's/.*\[\(.*\) ns.*/\1/' | awk '{print $1}')
          if [ ! -z "$ROUTE_TIME" ]; then
            ROUTE_NUM=$(echo "$ROUTE_TIME" | tr -d '[:alpha:][:space:]')
            if [ $(echo "$ROUTE_NUM > 1000" | bc -l 2>/dev/null || echo "0") -eq 1 ]; then
              echo "::error::Route matching exceeds 1μs target: ${ROUTE_TIME}ns"
              FAILED=1
            else
              echo "✓ Route matching: ${ROUTE_TIME}ns (target: <1μs)"
            fi
          fi

          # Check TLS fingerprint < 10μs target
          TLS_TIME=$(grep -A1 "TLSFingerprint/compute_full" benchmark-results.txt | grep "time:" | head -1 | sed 's/.*\[\(.*\) µs.*/\1/' | awk '{print $1}')
          if [ ! -z "$TLS_TIME" ]; then
            TLS_NUM=$(echo "$TLS_TIME" | tr -d '[:alpha:][:space:]')
            if [ $(echo "$TLS_NUM > 10" | bc -l 2>/dev/null || echo "0") -eq 1 ]; then
              echo "::error::TLS fingerprint exceeds 10μs target: ${TLS_TIME}μs"
              FAILED=1
            else
              echo "✓ TLS fingerprint: ${TLS_TIME}μs (target: <10μs)"
            fi
          fi

          # Check CRDT operations < 1μs target
          CRDT_TIME=$(grep -A1 "CRDT/increment" benchmark-results.txt | grep "time:" | head -1 | sed 's/.*\[\(.*\) ns.*/\1/' | awk '{print $1}')
          if [ ! -z "$CRDT_TIME" ]; then
            CRDT_NUM=$(echo "$CRDT_TIME" | tr -d '[:alpha:][:space:]')
            if [ $(echo "$CRDT_NUM > 1000" | bc -l 2>/dev/null || echo "0") -eq 1 ]; then
              echo "::error::CRDT operations exceed 1μs target: ${CRDT_TIME}ns"
              FAILED=1
            else
              echo "✓ CRDT increment: ${CRDT_TIME}ns (target: <1μs)"
            fi
          fi

          if [ $FAILED -eq 1 ]; then
            echo ""
            echo "::error::Performance targets not met. Review benchmarks above."
            exit 1
          fi

          echo ""
          echo "✓ All performance targets met!"

      - name: Save baseline (main branch only)
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        uses: actions/cache@v4
        with:
          path: ./node/target/criterion
          key: criterion-baseline-main-${{ github.sha }}

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: node/benchmark-results.txt
          retention-days: 30

      - name: Comment on PR
        if: github.event_name == 'pull_request' && steps.extract.outputs.regression_count > 0
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const results = fs.readFileSync('node/benchmark-results.txt', 'utf8');

            // Find regression lines
            const regressions = results.split('\n')
              .filter(line => line.includes('regressed'))
              .slice(0, 10);

            if (regressions.length > 0) {
              const body = `## ⚠️ Performance Regression Detected

            The following benchmarks show regression:

            \`\`\`
            ${regressions.join('\n')}
            \`\`\`

            Please review the changes and consider optimizations.

            <details>
            <summary>Full benchmark output</summary>

            \`\`\`
            ${results.slice(0, 50000)}
            \`\`\`
            </details>`;

              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: body
              });
            }

  # Separate job for unit tests (faster feedback)
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./node

    steps:
      - uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-action@stable

      - name: Cache cargo registry
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            node/target
          key: ${{ runner.os }}-cargo-test-${{ hashFiles('**/Cargo.lock') }}

      - name: Run tests
        run: cargo test --lib --bins

  # Optional: k6 load tests (requires running service)
  # load-tests:
  #   name: k6 Load Tests
  #   runs-on: ubuntu-latest
  #   needs: [benchmarks, unit-tests]
  #   if: github.ref == 'refs/heads/main'
  #
  #   steps:
  #     - uses: actions/checkout@v4
  #
  #     - name: Install k6
  #       run: |
  #         sudo gpg -k
  #         sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg \
  #           --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
  #         echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" \
  #           | sudo tee /etc/apt/sources.list.d/k6.list
  #         sudo apt-get update && sudo apt-get install k6
  #
  #     - name: Start AEGIS node
  #       run: |
  #         cd node
  #         cargo build --release
  #         ./target/release/aegis-node &
  #         sleep 5
  #
  #     - name: Run k6 load test
  #       run: k6 run node/k6/load-test.js --out json=results.json
  #
  #     - name: Upload k6 results
  #       uses: actions/upload-artifact@v4
  #       with:
  #         name: k6-results
  #         path: results.json
